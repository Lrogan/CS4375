{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Training set: X\n",
    "### Preprocessing (feature scaling/mean normalization)\n",
    "$$ u_{i} = \\frac{1}{m} \\sum\\limits_{i = 1}^{m} (x^{(i)}) $$\n",
    "\n",
    "### Replace each $$x_{i}$$ with $$x_{i} - u_{i}$$\n",
    "\n",
    "### If different features on different scales e.g. $$x_{1}= size of house $$ $$x_{2}= number of bedrooms $$\n",
    "### then scale features to have comparable range of values\n",
    "\n",
    "## Principal Component Analysis (PCA) algorithm\n",
    "\n",
    ">**Reduce data from n-dimensions to k-dimensions:**  \n",
    "**Compute \"covariance matrix: \"** $\\sum = \\frac{1}{m} \\sum\\limits_{i = 1}^{m} (x^{(i)}) (x^{(i)})^{(T)}$  \n",
    "**[U, S, V] = svd(Sigma);**\n",
    "**Compute \"eigenvectors\" of matrix:** $\\sum$\n",
    "\n",
    ">**svd = Single Value Decompisition**  \n",
    "**Other libararies: eig(Sigma)**  \n",
    "**U is nxn matrix**\n",
    "\n",
    ">**Ureduce = U(:,1:k)**  \n",
    "**z = Ureduce** $^{(T)}$ * **X** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCP will find the most important features even if they don't exist within the excel(it might make composite features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90b2864b0195a5508ac774f00def394741627176797bec63e4b6717effc2fb31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
